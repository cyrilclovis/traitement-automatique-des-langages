import nltk
from nltk.stem import WordNetLemmatizer
from nltk.corpus import wordnet
from nltk.tokenize import word_tokenize
from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer

from src.commands.command import Command
from src.utils.helpers import pathExists
from src.commands.creation.command_builder import CommandBuilder

# T√©l√©chargement des ressources pour NLTK
nltk.download('wordnet')
nltk.download('punkt')
nltk.download('punkt_tab')
nltk.download('averaged_perceptron_tagger')
nltk.download('averaged_perceptron_tagger_eng')

class LemmatizerCommand(Command):
    def __init__(self, lang_code: str, input_file: str, output_file: str):
        """
        Initialise le lemmatizer avec la langue, les fichiers d'entr√©e et sortie, et le chemin de config.
        """
        self.lang_code = lang_code
        self.input_file = input_file
        self.output_file = output_file

        self.file_already_exists = False
        if pathExists(output_file):
            self.file_already_exists = True

        # S√©lection du lemmatizer
        if lang_code == "en":
            self.lemmatizer = WordNetLemmatizer()
        elif lang_code == "fr":
            self.lemmatizer = FrenchLefffLemmatizer()
        else:
            raise ValueError("Langue non support√©e. Utiliser 'fr' ou 'en'.")


    def get_wordnet_pos(self, word):
        """
        Important: WordNetLemmatizer a besoin d'√©tiquettes grammaticales (pos). Vrai pour l'anglais, on peut s'en passer
        en francais car la forme d'un mot donne souvent assez d'information pour retrouver son lemme (ex: chantais, chant√©, chantons => chanter)
        """
        tag = nltk.pos_tag([word])[0][1][0].upper()
        tag_dict = {"J": wordnet.ADJ, "N": wordnet.NOUN, "V": wordnet.VERB, "R": wordnet.ADV}
        return tag_dict.get(tag, wordnet.NOUN)


    def lemmatize_text(self, text: str) -> str:
        """Lemmatisation d'un texte selon la langue sp√©cifi√©e."""
        tokens = word_tokenize(text) if self.lang_code == "en" else text.split()
        if self.lang_code == "en":
            lemmatized_tokens = [self.lemmatizer.lemmatize(token, self.get_wordnet_pos(token)) for token in tokens]
        else:
            lemmatized_tokens = [self.lemmatizer.lemmatize(token) for token in tokens]
        return " ".join(lemmatized_tokens)


    def lemmatize_corpus(self):
        """
        Applique la lemmatisation au fichier d'entr√©e et √©crit le r√©sultat dans le fichier de sortie.
        """
        with open(self.input_file, 'r', encoding='utf-8') as infile, open(self.output_file, 'w', encoding='utf-8') as outfile:
            for line in infile:
                lemmatized_line = self.lemmatize_text(line.strip())
                outfile.write(lemmatized_line + '\n')


    def execute(self):
        """
        Ex√©cute la lemmatisation et sauvegarde la configuration.
        """
        if self.file_already_exists:
            return CommandBuilder.build_command(f"echo \"üì¢ {self.output_file} existe d√©j√†.\"").execute()
        return self.lemmatize_corpus()


if __name__ == "__main__":
    command = LemmatizerCommand(lang_code="fr", input_file="test_fr.txt", output_file="output_fr.txt")
    command.execute()